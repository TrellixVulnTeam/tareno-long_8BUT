import hashlib
import logging

import pandas as pd
import sqlalchemy
from sqlalchemy import Table, Column, Integer, Float, Boolean, String, DateTime, MetaData
from sqlalchemy import select, literal, union_all
from sqlalchemy.engine import Engine
from sqlalchemy.sql import Select

from sray_db.psql.cnxn import get_meta, lock

logger = logging.getLogger(__name__)

MAX_ROW_INSERT = 10000
TYPE_MAP = {'int64': Integer,
            'float64': Float,
            'bool': Boolean,
            'object': String,
            'datetime64[ns]': DateTime}


def temptable_from_idx(idx: pd.MultiIndex, engine: Engine, min_count: int = 500):

    meta = get_meta(engine, 'load_idx')

    if len(idx) >= min_count:
        # Create temptable

        if not idx.is_monotonic_increasing:
            idx = idx.sort_values()

        tbl_name = _get_index_hash(idx)

        with lock:
            fullname = f'{meta.schema}.{tbl_name}'
            try:
                table = meta.tables[fullname]
            except KeyError:\
                table = _generate_table_from_index(idx, meta, tbl_name)

            if not table.exists():
                try:
                    _populate_table(table, idx)
                except (sqlalchemy.exc.IntegrityError, sqlalchemy.exc.ProgrammingError) as e:
                    if table.exists():
                        logger.debug(f'Race condition: table {table.fullname} was already created by another process, '
                                     f'aborting transaction and returning the existing table.')
                    else:
                        raise e

    else:
        table = _make_literals_select_statement(idx)

    return table


def _get_index_hash(idx: pd.Index) -> str:
    """Calculate the md5 hash (hexdigest) of a pandas Index"""

    idx_names = "_".join(str(n.name) for n in idx.names).encode('utf-8')
    idx_len = str(len(idx)).encode('utf-8')
    idx_values = str(idx.to_list()).encode('utf-8')
    idx_hash = hashlib.md5(idx_names + idx_len + idx_values).hexdigest()

    return idx_hash


def _populate_table(table: Table, idx: pd.Index):
    """Create table, add data from idx to table and persist to Database"""

    is_multi_index = idx.nlevels > 1

    if is_multi_index:
        rows = [r for r in idx]
    else:
        rows = [(r, ) for r in idx]

    with table.bind.begin() as conn:
        table.create(bind=conn)
        logger.debug(f'Created table {table.fullname}')
        chunked = [rows[i:i + MAX_ROW_INSERT] for i in range(0, len(rows), MAX_ROW_INSERT)]

        for row in chunked:
            conn.execute(table.insert(row))


def _generate_table_from_index(idx: pd.Index, meta: MetaData, table_name: str) -> Table:
    """Create a SQLAlchemy Table (without persisting) based on a pandas Index"""

    is_multi_index = idx.nlevels > 1

    columns = []
    for i in range(idx.nlevels):
        lvl = idx.levels[i] if is_multi_index else idx
        dtype = TYPE_MAP.get(lvl.dtype.name, String)
        columns.append(Column(lvl.name.value, dtype, index=True))

    table = Table(table_name, meta, *columns)

    return table


def _make_literals_select_statement(idx: pd.Index) -> Select:
    """Convert index into a Select statement by converting all data items into literals and selecting them all with
    UNION ALL. This statement is faster to generate for small indexes (but slower to query for big indexes) since there
    is no overhead to create and persist a table."""

    is_multi_index = idx.nlevels > 1

    labels = []
    types = []
    for i in range(idx.nlevels):
        lvl = idx.levels[i] if is_multi_index else idx
        dtype = TYPE_MAP.get(lvl.dtype.name, String)
        labels.append(lvl.name.value)
        types.append(dtype)

    all_selects = []
    for row in idx.tolist():
        if not is_multi_index:
            row = [row]
        to_select = list(zip(row, labels, types))
        s = select([literal(val).cast(type_).label(lbl) for val, lbl, type_ in to_select])
        all_selects.append(s)

    table = union_all(*all_selects)

    return table
